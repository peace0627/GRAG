#!/usr/bin/env python3
"""
ç›´æ¥æ¸¬è©¦å‘é‡æœç´¢é‚è¼¯
"""

import asyncio
import os
import sys
import numpy as np
from supabase import create_client

async def test_vector_search_direct():
    try:
        # å¾.envæ–‡ä»¶è®€å–Supabaseè¨­ç½®
        env_file = '.env'
        supabase_url = None
        supabase_key = None

        with open(env_file, 'r') as f:
            for line in f:
                line = line.strip()
                if line.startswith('SUPABASE_URL='):
                    supabase_url = line.split('=', 1)[1]
                elif line.startswith('SUPABASE_KEY='):
                    supabase_key = line.split('=', 1)[1]

        supabase_url = supabase_url or os.getenv('SUPABASE_URL')
        supabase_key = supabase_key or os.getenv('SUPABASE_KEY')

        if not supabase_url or not supabase_key:
            print("âŒ ç„¡æ³•ç²å– SUPABASE_URL æˆ– SUPABASE_KEY")
            return

        print("ğŸ”— é€£æ¥Supabase...")
        supabase = create_client(supabase_url, supabase_key)

        # æ¸¬è©¦1: æª¢æŸ¥å‘é‡æ•¸æ“š
        print("\nğŸ“Š æ¸¬è©¦1: æª¢æŸ¥å‘é‡æ•¸æ“š")
        response = supabase.table('vectors').select('*').limit(5).execute()
        print(f"âœ… ç²å–åˆ° {len(response.data)} æ¢å‘é‡è¨˜éŒ„")

        if response.data:
            for i, record in enumerate(response.data):
                embedding = record.get('embedding', [])
                print(f"  è¨˜éŒ„ {i+1}: vector_id={record.get('vector_id')[:8]}..., type={record.get('type')}, embedding_length={len(embedding)}")
                if len(embedding) > 0:
                    print(f"    åµŒå…¥æ¨£æœ¬: {embedding[:3]}...")

        # æ¸¬è©¦2: ç›´æ¥ç›¸ä¼¼åº¦è¨ˆç®—
        print("\nğŸ” æ¸¬è©¦2: ç›´æ¥ç›¸ä¼¼åº¦è¨ˆç®—")

        # ç”Ÿæˆæ¸¬è©¦æŸ¥è©¢çš„åµŒå…¥
        from sentence_transformers import SentenceTransformer
        model = SentenceTransformer('all-MiniLM-L6-v2')
        test_query = "510(k)"
        query_embedding = model.encode(test_query)
        print(f"æŸ¥è©¢ '{test_query}' çš„åµŒå…¥é•·åº¦: {len(query_embedding)}")
        print(f"æŸ¥è©¢åµŒå…¥æ¨£æœ¬: {query_embedding[:3]}")

        # ç²å–æ‰€æœ‰å‘é‡ä¸¦è¨ˆç®—ç›¸ä¼¼åº¦
        all_vectors = supabase.table('vectors').select('*').execute()
        print(f"æ•¸æ“šåº«ä¸­æœ‰ {len(all_vectors.data)} æ¢å‘é‡è¨˜éŒ„")

        similarities = []
        query_vec = np.array(query_embedding)

        for record in all_vectors.data:
            # è™•ç†JSONBæ•¸æ“š - å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨
            embedding_data = record['embedding']
            if isinstance(embedding_data, str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå˜—è©¦è§£æJSON
                import json
                try:
                    embedding_data = json.loads(embedding_data)
                except:
                    print(f"âš ï¸ ç„¡æ³•è§£æå‘é‡å­—ç¬¦ä¸²: {embedding_data[:50]}...")
                    continue

            db_embedding = np.array(embedding_data)

            # æª¢æŸ¥å‘é‡é•·åº¦
            if len(db_embedding) != len(query_vec):
                print(f"âš ï¸ å‘é‡é•·åº¦ä¸åŒ¹é…: æŸ¥è©¢={len(query_vec)}, æ•¸æ“šåº«={len(db_embedding)}")
                continue

            # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
            similarity = np.dot(query_vec, db_embedding) / (np.linalg.norm(query_vec) * np.linalg.norm(db_embedding))
            similarities.append((similarity, record))

            print(".3f")

        # æ’åºä¸¦é¡¯ç¤ºtopçµæœ
        similarities.sort(key=lambda x: x[0], reverse=True)
        top_results = similarities[:3]

        print("\nç›¸ä¼¼åº¦è¨ˆç®—çµæœ (top 3):")
        for i, (sim, record) in enumerate(top_results):
            print(".3f")
            if sim > 0.1:  # å¦‚æœæœ‰ç›¸ä¼¼åº¦>0.1ï¼Œé¡¯ç¤ºå…§å®¹
                # å˜—è©¦ç²å–chunkå…§å®¹
                chunk_id = record.get('chunk_id')
                if chunk_id:
                    print(f"      å…§å®¹: {record.get('content_preview', 'No preview')[:100]}...")

        # æ¸¬è©¦3: æª¢æŸ¥æ˜¯å¦æœ‰å¾ˆé«˜ç›¸ä¼¼åº¦çš„çµæœ
        high_similarity = [s for s, r in similarities if s > 0.1]
        print(f"\nğŸ“ˆ é«˜ç›¸ä¼¼åº¦çµæœ (>0.1): {len(high_similarity)} å€‹")

        if len(high_similarity) == 0:
            print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•ç›¸ä¼¼åº¦>0.1çš„çµæœï¼")

            # æª¢æŸ¥ç›¸ä¼¼åº¦åˆ†ä½ˆ
            all_similarities = [s for s, r in similarities]
            print(f"ç›¸ä¼¼åº¦ç¯„åœ: {min(all_similarities):.3f} - {max(all_similarities):.3f}")
            print(f"ç›¸ä¼¼åº¦å¹³å‡å€¼: {np.mean(all_similarities):.3f}")

    except Exception as e:
        print(f"âŒ å‘é‡æœç´¢æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_vector_search_direct())
