#!/usr/bin/env python3
"""
ç›´æ¥æ¸¬è©¦å‘é‡æœç´¢åŠŸèƒ½
"""

import asyncio
import os
import sys
import pytest
from supabase import create_client

@pytest.mark.asyncio
async def test_vector_search():
    try:
        # å¾.envæ–‡ä»¶è®€å–Supabaseè¨­ç½®
        env_file = '.env'
        supabase_url = None
        supabase_key = None

        if os.path.exists(env_file):
            with open(env_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line.startswith('SUPABASE_URL='):
                        supabase_url = line.split('=', 1)[1]
                    elif line.startswith('SUPABASE_KEY='):
                        supabase_key = line.split('=', 1)[1]

        supabase_url = supabase_url or os.getenv('SUPABASE_URL')
        supabase_key = supabase_key or os.getenv('SUPABASE_KEY')

        if not supabase_url or not supabase_key:
            print("âŒ ç„¡æ³•ç²å– SUPABASE_URL æˆ– SUPABASE_KEY")
            return

        print(f"ğŸ”— é€£æ¥Supabase: {supabase_url}")

        # å‰µå»ºSupabaseå®¢æˆ¶ç«¯
        supabase = create_client(supabase_url, supabase_key)

        # æ¸¬è©¦1: æª¢æŸ¥å‘é‡æ•¸æ“š
        print("\nğŸ“Š æ¸¬è©¦1: æª¢æŸ¥å‘é‡æ•¸æ“š")
        response = supabase.table('vectors').select('*').limit(3).execute()
        print(f"âœ… ç²å–åˆ° {len(response.data)} æ¢å‘é‡è¨˜éŒ„")

        if response.data:
            for i, record in enumerate(response.data):
                embedding = record.get('embedding', [])
                print(f"  è¨˜éŒ„ {i+1}: vector_id={record.get('vector_id')}, type={record.get('type')}, embedding_length={len(embedding)}")
                if len(embedding) > 0:
                    print(f"    åµŒå…¥æ¨£æœ¬: {embedding[:5]}...")

        # æ¸¬è©¦2: ç›´æ¥ç›¸ä¼¼åº¦è¨ˆç®—
        print("\nğŸ” æ¸¬è©¦2: ç›´æ¥ç›¸ä¼¼åº¦è¨ˆç®—")
        import numpy as np
        from sentence_transformers import SentenceTransformer

        # åŠ è¼‰embeddingæ¨¡å‹
        model = SentenceTransformer('all-MiniLM-L6-v2')

        # ç”Ÿæˆæ¸¬è©¦æŸ¥è©¢çš„åµŒå…¥
        test_query = "510(k)"
        query_embedding = model.encode(test_query)
        print(f"æŸ¥è©¢ '{test_query}' çš„åµŒå…¥é•·åº¦: {len(query_embedding)}")

        # ç²å–æ‰€æœ‰å‘é‡ä¸¦è¨ˆç®—ç›¸ä¼¼åº¦
        all_vectors = supabase.table('vectors').select('*').execute()

        similarities = []
        query_vec = np.array(query_embedding)

        for record in all_vectors.data:
            db_embedding = np.array(record['embedding'])

            # ç¢ºä¿å‘é‡é•·åº¦åŒ¹é…
            if len(db_embedding) != len(query_vec):
                print(f"âš ï¸ å‘é‡é•·åº¦ä¸åŒ¹é…: æŸ¥è©¢={len(query_vec)}, æ•¸æ“šåº«={len(db_embedding)}")
                continue

            # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
            similarity = np.dot(query_vec, db_embedding) / (np.linalg.norm(query_vec) * np.linalg.norm(db_embedding))
            similarities.append((similarity, record))

        # æ’åºä¸¦é¡¯ç¤ºtopçµæœ
        similarities.sort(key=lambda x: x[0], reverse=True)
        top_results = similarities[:3]

        print(f"ç›¸ä¼¼åº¦è¨ˆç®—çµæœ (top 3):")
        for i, (sim, record) in enumerate(top_results):
            print(".3f")

        # æ¸¬è©¦3: æª¢æŸ¥æ˜¯å¦æœ‰å¾ˆé«˜ç›¸ä¼¼åº¦çš„çµæœ
        high_similarity = [s for s, r in similarities if s > 0.5]
        print(f"é«˜ç›¸ä¼¼åº¦çµæœ (>0.5): {len(high_similarity)} å€‹")

    except Exception as e:
        print(f"âŒ å‘é‡æœç´¢æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_vector_search())
