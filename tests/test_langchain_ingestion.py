#!/usr/bin/env python3
"""Test script for LangChain-enhanced ingestion service"""

import sys
import os
from pathlib import Path
import unittest.mock as mock

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import asyncio
import tempfile
import logging

from grag.ingestion.indexing.ingestion_service import IngestionService
from grag.ingestion.langchain_loader import LangChainDocumentLoader, DocumentProcessingStrategy, StructuredTextFallback
from grag.ingestion.indexing.chunking_service import ChunkingService
from grag.ingestion.indexing.embedding_service import EmbeddingService

# Set up logging
logging.basicConfig(level=logging.INFO)

async def test_langchain_components():
    """Test individual LangChain components without database dependencies"""

    print("ğŸš€ æ¸¬è©¦LangChainå…ƒä»¶")
    print("=" * 50)

    # Test 1: Document Loader
    print("ğŸ§ª æ¸¬è©¦1: LangChainæ–‡æª”è¼‰å…¥å™¨")
    loader = LangChainDocumentLoader()

    test_content = """
# æ¸¬è©¦æ–‡æª”

é€™æ˜¯ä¸€å€‹æ¸¬è©¦Markdownæ–‡ä»¶ã€‚

## ç« ç¯€

- é …ç›®1
- é …ç›®2

| æ¬„ä½ | å€¼ |
|------|----|
| æ¸¬è©¦ | âœ… |
"""

    # Create temporary test file
    with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
        f.write(test_content)
        test_file_path = Path(f.name)

    try:
        langchain_docs = await loader.load_document(test_file_path)
        print(f"âœ… è¼‰å…¥æ–‡æª”æˆåŠŸ: {len(langchain_docs)} å€‹chunks")

        combined_text = loader.combine_documents(langchain_docs)
        print(f"ğŸ“ åˆä½µå¾Œé•·åº¦: {len(combined_text)} å­—ç¬¦")

        # Test 2: Processing Strategy
        print("\nğŸ§ª æ¸¬è©¦2: æ–‡ä»¶è™•ç†ç­–ç•¥")
        strategy = DocumentProcessingStrategy()

        # Test different file types
        test_files = {
            test_file_path: False,  # .md should skip VLM (can process directly)
            test_file_path.with_suffix('.pdf'): True,  # .pdf should use VLM
            test_file_path.with_suffix('.txt'): False,  # .txt should skip VLM (can process directly)
        }

        for file_path, expect_vlm in test_files.items():
            use_vlm = strategy.should_use_vlm_first(file_path)
            print(f"ğŸ“„ {file_path.suffix}: {'ä½¿ç”¨VLM' if use_vlm else 'è·³éVLM'} "
                  f"(é æœŸ: {'ä½¿ç”¨VLM' if expect_vlm else 'è·³éVLM'})")

        # Test override
        force_skip = strategy.should_use_vlm_first(test_file_path.with_suffix('.pdf'), use_vlm_override=False)
        force_use = strategy.should_use_vlm_first(test_file_path.with_suffix('.txt'), use_vlm_override=True)
        print(f"ğŸ”§ å¼·åˆ¶è¦†å¯« - è·³éPDF VLM: {not force_skip}, å¼·åˆ¶ä½¿ç”¨TXT VLM: {force_use}")

        # Test 3: Structured Fallback
        print("\nğŸ§ª æ¸¬è©¦3: çµæ§‹åŒ–æ–‡å­—é™ç´šè™•ç†")
        fallback = StructuredTextFallback()

        # Mock LangChain documents
        from langchain_core.documents import Document as LangchainDocument
        mock_docs = [LangchainDocument(page_content=combined_text)]

        vlm_output = await fallback.create_structured_output(mock_docs, test_file_path, "test_file_id")
        print(f"âœ… çµæ§‹åŒ–è¼¸å‡º - å€åŸŸæ•¸: {len(vlm_output.regions)}, è¡¨æ ¼æ•¸: {len(vlm_output.tables)}")
        print(f"ğŸ“Š å“è³ªç­‰ç´š: {vlm_output.metadata.get('quality_level', 'unknown') if vlm_output.metadata else 'unknown'}")

        if vlm_output.regions:
            print("ğŸ¯ ç¤ºä¾‹å€åŸŸ:")
            for i, region in enumerate(vlm_output.regions[:3]):
                print(f"  {i+1}. {region.modality}: {region.description[:50]}...")

        # Test 4: Chunking Service
        print("\nğŸ§ª æ¸¬è©¦4: åˆ†å¡Šæœå‹™")
        chunker = ChunkingService()
        from uuid import UUID, uuid4
        test_uuid = uuid4()

        chunks = chunker.chunk_text(combined_text, test_uuid)
        print(f"âœ… åˆ†å¡ŠæˆåŠŸ: {len(chunks)} å€‹chunks")
        if chunks:
            chunk_sizes = [chunk['metadata']['chunk_size'] for chunk in chunks]
            print(f"ğŸ“ Chunkå¤§å°çµ±è¨ˆ: æœ€å°{chunk_sizes[0]}, æœ€å¤§{chunk_sizes[-1]}, ç¸½å­—ç¬¦: {sum(chunk_sizes)}")

        print(f"\n{'='*50}")
        print("ğŸ‰ LangChainå…ƒä»¶æ¸¬è©¦å®Œæˆ!")

        return True

    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        # Clean up
        if test_file_path.exists():
            test_file_path.unlink()


async def main():
    """Main test runner"""
    success = await test_langchain_components()
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    asyncio.run(main())
