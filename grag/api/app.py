"""
FastAPI Application
GraphRAGç³»çµ±çš„REST APIæœå‹™
æä¾›æ–‡ä»¶ä¸Šå‚³ã€æª¢ç´¢ã€åˆ é™¤å’Œç®¡ç†åŠŸèƒ½
"""

from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
from typing import List, Optional, Dict, Any
from pathlib import Path
import tempfile
import shutil
import json
from datetime import datetime

# å°å…¥æ ¸å¿ƒæœå‹™
from grag.core.health_service import HealthService
from grag.core.database_services import DatabaseManager
from grag.ingestion.indexing.ingestion_service import IngestionService

# å‰µå»ºFastAPIæ‡‰ç”¨
app = FastAPI(
    title="GraphRAG API",
    description="åœ–å½¢åŒ–æª¢ç´¢å¢å¼·ç”Ÿæˆç³»çµ±çš„REST API",
    version="1.0.0"
)

# CORSè¨­ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–æ ¸å¿ƒæœå‹™
health_service = HealthService()

def get_database_manager():
    """ç²å–è³‡æ–™åº«ç®¡ç†å™¨å¯¦ä¾‹"""
    from grag.core.config import settings
    return DatabaseManager(
        neo4j_uri=settings.neo4j_uri,
        neo4j_user=settings.neo4j_user,
        neo4j_password=settings.neo4j_password,
        supabase_url=settings.supabase_url,
        supabase_key=settings.supabase_key
    )

@app.get("/")
async def root():
    """APIæ ¹ç«¯é»"""
    return {"message": "GraphRAG API", "version": "1.0.0", "status": "running"}

@app.get("/health")
async def health_check():
    """ç³»çµ±å¥åº·æª¢æŸ¥"""
    try:
        status = health_service.get_system_status()
        return {
            "status": "healthy",
            "timestamp": status["timestamp"],
            "overall_health": status["overall_health"],
            "services": status
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Health check failed: {str(e)}")

@app.post("/upload/single")
async def upload_single_file(
    file: UploadFile = File(...),
    force_vlm: Optional[bool] = None
):
    """ä¸Šå‚³å–®å€‹æ–‡ä»¶é€²è¡Œè™•ç†"""
    try:
        # é©—è­‰æ–‡ä»¶é¡å‹
        allowed_extensions = ['.pdf', '.docx', '.txt', '.md']
        file_ext = Path(file.filename).suffix.lower()

        if file_ext not in allowed_extensions:
            raise HTTPException(
                status_code=400,
                detail=f"Unsupported file type. Allowed: {', '.join(allowed_extensions)}"
            )

        # å‰µå»ºè‡¨æ™‚æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_file:
            shutil.copyfileobj(file.file, temp_file)
            temp_path = Path(temp_file.name)

        # åˆå§‹åŒ–è™•ç†æœå‹™
        ingestion_service = IngestionService()

        # é€²è¡Œæ–‡ä»¶è™•ç†
        result = await ingestion_service.ingest_document_enhanced(
            file_path=temp_path,
            force_vlm=force_vlm
        )

        # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
        temp_path.unlink(missing_ok=True)

        if result.get("success"):
            return {
                "success": True,
                "message": f"File '{file.filename}' processed successfully",
                "data": result
            }
        else:
            raise HTTPException(
                status_code=500,
                detail=result.get("error", "Processing failed")
            )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")

@app.post("/upload/batch")
async def upload_batch_files(
    files: List[UploadFile] = File(...),
    force_vlm: Optional[bool] = None
):
    """æ‰¹é‡ä¸Šå‚³å¤šå€‹æ–‡ä»¶é€²è¡Œè™•ç†"""
    if len(files) > 10:  # é™åˆ¶æ‰¹æ¬¡å¤§å°
        raise HTTPException(status_code=400, detail="Maximum 10 files per batch")

    results = []
    total_success = 0
    total_failed = 0

    try:
        ingestion_service = IngestionService()

        for file in files:
            try:
                # é©—è­‰æ–‡ä»¶é¡å‹
                file_ext = Path(file.filename).suffix.lower()
                allowed_extensions = ['.pdf', '.docx', '.txt', '.md']

                if file_ext not in allowed_extensions:
                    results.append({
                        "filename": file.filename,
                        "success": False,
                        "error": f"Unsupported file type"
                    })
                    total_failed += 1
                    continue

                # å‰µå»ºè‡¨æ™‚æ–‡ä»¶
                with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_file:
                    shutil.copyfileobj(file.file, temp_file)
                    temp_path = Path(temp_file.name)

                # è™•ç†æ–‡ä»¶
                result = await ingestion_service.ingest_document_enhanced(
                    file_path=temp_path,
                    force_vlm=force_vlm
                )

                # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
                temp_path.unlink(missing_ok=True)

                if result.get("success"):
                    results.append({
                        "filename": file.filename,
                        "success": True,
                        "data": result.get("metadata", {})
                    })
                    total_success += 1
                else:
                    results.append({
                        "filename": file.filename,
                        "success": False,
                        "error": result.get("error", "Processing failed")
                    })
                    total_failed += 1

            except Exception as e:
                results.append({
                    "filename": file.filename,
                    "success": False,
                    "error": str(e)
                })
                total_failed += 1

        return {
            "success": True,
            "message": f"Batch processing completed. Success: {total_success}, Failed: {total_failed}",
            "results": results,
            "statistics": {
                "total_files": len(files),
                "successful": total_success,
                "failed": total_failed
            }
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Batch upload failed: {str(e)}")

@app.delete("/documents/{document_id}")
async def delete_document(document_id: str):
    """åˆ é™¤æŒ‡å®šçš„æ–‡æª”åŠå…¶æ‰€æœ‰é—œè¯æ•¸æ“š"""
    try:
        from uuid import UUID
        doc_uuid = UUID(document_id)

        db_manager = get_database_manager()
        await db_manager.initialize()

        result = await db_manager.delete_document_cascade(doc_uuid)
        await db_manager.close()

        if result:
            return {
                "success": True,
                "message": f"Document {document_id} and all associated data deleted successfully"
            }
        else:
            raise HTTPException(status_code=404, detail="Document not found or deletion failed")

    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid document ID format")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Deletion failed: {str(e)}")

@app.delete("/documents/batch")
async def delete_batch_documents(document_ids: List[str]):
    """æ‰¹é‡åˆ é™¤å¤šå€‹æ–‡æª”"""
    try:
        from uuid import UUID

        # æ ¼å¼é©—è­‰
        doc_uuids = []
        for doc_id in document_ids:
            try:
                doc_uuids.append(UUID(doc_id))
            except ValueError:
                raise HTTPException(
                    status_code=400,
                    detail=f"Invalid document ID format: {doc_id}"
                )

        db_manager = get_database_manager()
        await db_manager.initialize()

        results = await db_manager.delete_documents_batch(doc_uuids)
        await db_manager.close()

        return {
            "success": True,
            "message": f"Batch deletion completed. Success: {results['successful_deletions']}, Failed: {len(results['failed_deletions'])}",
            "details": results
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Batch deletion failed: {str(e)}")

@app.get("/documents")
async def list_documents(limit: int = 50, offset: int = 0):
    """ç²å–å·²è™•ç†çš„æ–‡æª”åˆ—è¡¨"""
    try:
        db_manager = get_database_manager()
        # é€™è£¡å¯ä»¥å¯¦ç¾ç´¢å¼•æŸ¥è©¢é‚è¼¯
        # ç›®å‰è¿”å›ç©ºçš„ï¼Œå› ç‚ºéœ€è¦ä¿®æ”¹DatabaseManager

        # ç°¡å–®çš„æ¨¡æ“¬å›æ‡‰
        return {
            "success": True,
            "documents": [],
            "pagination": {
                "limit": limit,
                "offset": offset,
                "total": 0
            },
            "message": "Document listing not yet implemented. Use database tools for now."
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to list documents: {str(e)}")

@app.post("/search")
async def search_documents(query: str, limit: int = 10):
    """æ ¹æ“šæŸ¥è©¢æœç´¢ç›¸é—œæ–‡æª”"""
    try:
        # é€™è£¡å°‡å¯¦ç¾RAGæª¢ç´¢é‚è¼¯
        # çµåˆNeo4jåœ–å½¢æŸ¥è©¢å’ŒSupabaseå‘é‡æª¢ç´¢

        return {
            "success": True,
            "query": query,
            "results": [],
            "message": "Advanced search not yet implemented. Will integrate LangGraph + pgvector.",
            "metadata": {
                "limit": limit,
                "total_results": 0
            }
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Search failed: {str(e)}")

@app.get("/statistics")
async def get_statistics():
    """ç²å–ç³»çµ±çµ±è¨ˆä¿¡æ¯"""
    try:
        # é€™è£¡å¯ä»¥å¯¦ç¾çµ±è¨ˆæŸ¥è©¢é‚è¼¯
        # æŸ¥è©¢Neo4jå’ŒSupabaseçš„æ•¸æ“šé‡ç­‰

        return {
            "success": True,
            "message": "Statistics not yet fully implemented. Use database tools for detailed stats.",
            "placeholder_data": {
                "total_documents": 0,
                "total_chunks": 0,
                "total_vectors": 0
            }
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get statistics: {str(e)}")

def main():
    """å•Ÿå‹•FastAPIæœå‹™"""
    import uvicorn
    print("ğŸš€ GraphRAG APIæœå‹™å•Ÿå‹•ä¸­...")
    print("ğŸ“Š æœå‹™ä¿¡æ¯:")
    print("  - APIåœ°å€: http://localhost:8000")
    print("  - æ–‡æª”åœ°å€: http://localhost:8000/docs")
    print()
    uvicorn.run("grag.api.app:app", host="0.0.0.0", port=8000, reload=True)

if __name__ == "__main__":
    main()
