#!/usr/bin/env python3
"""
LangChainå¢å¼·è™•ç†æ¸¬è©¦GUI

é€™å€‹Streamlitæ‡‰ç”¨ç”¨æ–¼æ¸¬è©¦å‰›å¯¦ç¾çš„LangChainå¢å¼·æ–‡æª”è™•ç†åŠŸèƒ½ï¼Œ
åŒ…æ‹¬æ–‡ä»¶è¼‰å…¥ã€VLMç­–ç•¥ã€é™ç´šè™•ç†ã€åˆ†å¡Šå’ŒåµŒå…¥ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚

ä½¿ç”¨æ–¹å¼:
    cd grag/frontend/
    uv run streamlit run app.py
"""

import sys
import os
from pathlib import Path
import asyncio
import tempfile
from typing import Dict, Any, Optional
import time

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import streamlit as st
from grag.ingestion.indexing.ingestion_service import IngestionService
from grag.core.config import settings

# é…ç½®é é¢
st.set_page_config(
    page_title="ğŸ”— LangChainè™•ç†æ¸¬è©¦å™¨",
    page_icon="ğŸ”—",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è¨­å®šä¸­æ–‡ç•Œé¢
st.markdown("""
<style>
    .stApp {
        font-family: 'Microsoft YaHei', sans-serif;
    }
</style>
""", unsafe_allow_html=True)

# ä¸»è¦æ¨™é¡Œ
st.title("ğŸ”— LangChainå¢å¼·æ–‡æª”è™•ç†æ¸¬è©¦å™¨")
st.markdown("---")

# å´é‚Šæ¬„é…ç½®
st.sidebar.title("âš™ï¸ è™•ç†é…ç½®")

# VLMç­–ç•¥é¸æ“‡
vlm_strategy = st.sidebar.selectbox(
    "ğŸ¯ VLMè™•ç†ç­–ç•¥",
    ["è‡ªå‹•åˆ¤æ–·", "å¼·åˆ¶é–‹å•Ÿ", "å¼·åˆ¶é—œé–‰"],
    help="""
    è‡ªå‹•åˆ¤æ–·: æ ¹æ“šæ–‡ä»¶é¡å‹æ™ºèƒ½é¸æ“‡ (.pdfä½¿ç”¨VLM, .txt/.mdç›´æ¥è™•ç†)
    å¼·åˆ¶é–‹å•Ÿ: å°æ‰€æœ‰æ–‡æª”éƒ½ä½¿ç”¨VLMè™•ç† (æœƒè§¸ç™¼é™ç´šé‚è¼¯)
    å¼·åˆ¶é—œé–‰: è·³éVLMï¼Œç›´æ¥ä½¿ç”¨çµæ§‹åŒ–æ–‡å­—è™•ç†
    """
)

# ç­–ç•¥å€’æ›
force_vlm_map = {
    "è‡ªå‹•åˆ¤æ–·": None,    # Noneä»£è¡¨è‡ªå‹•
    "å¼·åˆ¶é–‹å•Ÿ": True,    # å¼·åˆ¶ä½¿ç”¨VLM
    "å¼·åˆ¶é—œé–‰": False    # å¼·åˆ¶è·³éVLM
}
force_vlm = force_vlm_map[vlm_strategy]

# ç­–ç•¥èªªæ˜
st.sidebar.markdown("**ç­–ç•¥é‚è¼¯èªªæ˜:**")
if vlm_strategy == "è‡ªå‹•åˆ¤æ–·":
    st.sidebar.info("""
    ğŸ“‹ **æ–‡ä»¶è™•ç†é‚è¼¯**:
    - `.pdf`, `.docx` â†’ VLMè™•ç† (è¦–è¦ºåˆ†æ)
    - `.txt`, `.md` â†’ ç›´æ¥è™•ç† (LangChainè¼‰å…¥)
    - å…¶ä»–æ ¼å¼ â†’ VLMå„ªå…ˆ (æœªçŸ¥å…§å®¹è¼ƒå®‰å…¨)
    """)
elif vlm_strategy == "å¼·åˆ¶é–‹å•Ÿ":
    st.sidebar.info("""
    ğŸ”§ **å¼·åˆ¶VLMæ¨¡å¼**:
    - å°æ‰€æœ‰æ–‡ä»¶å˜—è©¦VLMè™•ç†
    - å¤±æ•—æ™‚è‡ªå‹•é™ç´šåˆ°çµæ§‹åŒ–æ–‡å­—åˆ†æ
    - é©åˆæ¸¬è©¦é™ç´šæ©Ÿåˆ¶
    """)
else:  # å¼·åˆ¶é—œé–‰
    st.sidebar.info("""
    ğŸ“ **ç›´æ¥è™•ç†æ¨¡å¼**:
    - è·³éVLMï¼Œç›´æ¥ä½¿ç”¨LangChainè¼‰å…¥
    - ä½¿ç”¨çµæ§‹åŒ–æ–‡å­—åˆ†æ
    - æœ€å¿«é€Ÿçš„è™•ç†æ–¹å¼
    """)

st.sidebar.markdown("---")

# ç³»çµ±ç‹€æ…‹æª¢æŸ¥
st.sidebar.markdown("### ğŸ” ç³»çµ±ç‹€æ…‹")

# æª¢æŸ¥LangChainå®‰è£
try:
    import langchain_community
    st.sidebar.success("âœ… LangChainå¯ç”¨")
except ImportError:
    st.sidebar.error("âŒ LangChainæœªå®‰è£")

# æª¢æŸ¥VLMé…ç½®
if settings.qwen2vl_api_key or settings.openai_api_key:
    st.sidebar.success("âœ… VLMæœå‹™å·²é…ç½®")
else:
    st.sidebar.warning("âš ï¸ VLMæœå‹™æœªé…ç½® (å°‡ä½¿ç”¨é™ç´šè™•ç†)")

# æª¢æŸ¥åµŒå…¥æœå‹™
try:
    from grag.ingestion.indexing.providers.embedding_providers import EmbeddingProviderManager
    st.sidebar.success("âœ… åµŒå…¥æœå‹™å¯ç”¨")
except Exception:
    st.sidebar.error("âŒ åµŒå…¥æœå‹™ç•°å¸¸")

st.sidebar.markdown("---")

# ä¸»é é¢
col1, col2 = st.columns([1, 2])

with col1:
    st.markdown("### ğŸ“¤ æ–‡ä»¶ä¸Šå‚³")

    # æ–‡ä»¶ä¸Šå‚³å™¨
    uploaded_file = st.file_uploader(
        "é¸æ“‡æ¸¬è©¦æ–‡æª”",
        type=["pdf", "docx", "txt", "md"],
        help="æ”¯æ´çš„æ–‡ä»¶æ ¼å¼: PDF, Word, æ–‡å­—, Markdown",
        key="uploaded_file"
    )

    if uploaded_file is not None:
        st.success(f"ğŸ“„ å·²é¸æ“‡: {uploaded_file.name}")

        # é¡¯ç¤ºæ–‡ä»¶è³‡è¨Š
        file_info = {
            "æ–‡ä»¶å": uploaded_file.name,
            "å¤§å°": f"{uploaded_file.size/1024:.1f} KB",
            "æ ¼å¼": Path(uploaded_file.name).suffix,
        }

        st.json(file_info)

        # VLMç­–ç•¥é©ç”¨æ€§æç¤º
        file_ext = Path(uploaded_file.name).suffix.lower()
        strategy_hint = {
            '.pdf': "å°‡ä½¿ç”¨VLMè™•ç†ï¼Œå› ç‚ºPDFéœ€è¦è¦–è¦ºåˆ†æ",
            '.docx': "å°‡å˜—è©¦VLMè™•ç†ï¼Œå¯å°è¤‡é›œæ ¼å¼çš„æ–‡ä»¶åˆ†æ",
            '.txt': "å°‡ç›´æ¥è™•ç†ï¼Œå› ç‚ºæ–‡å­—æ ¼å¼é©åˆLangChainè¼‰å…¥",
            '.md': "å°‡ç›´æ¥è™•ç†ï¼Œå› ç‚ºMarkdowné©åˆçµæ§‹åŒ–è§£æ"
        }

        if file_ext in strategy_hint:
            if vlm_strategy == "è‡ªå‹•åˆ¤æ–·":
                st.info(f"ğŸ¯ {strategy_hint[file_ext]}")
            else:
                st.info(f"ğŸ”§ æ‰‹å‹•ç­–ç•¥: {vlm_strategy}")

        # è™•ç†æŒ‰éˆ•
        process_button = st.button("ğŸš€ é–‹å§‹è™•ç†", type="primary", use_container_width=True)

    else:
        st.info("è«‹ä¸Šå‚³ä¸€å€‹æ–‡ä»¶ä¾†é–‹å§‹æ¸¬è©¦")
        process_button = False

with col2:
    st.markdown("### ğŸ“Š è™•ç†çµæœ")

    # æª¢æŸ¥æ˜¯å¦å¯ä»¥è™•ç†
    if not (process_button and uploaded_file is not None):
        st.info("â¬…ï¸ è«‹å…ˆä¸Šå‚³æ–‡ä»¶ä¸¦é»æ“Šè™•ç†æŒ‰éˆ•")
    else:
        # å‰µå»ºé€²åº¦æ¢
        progress_bar = st.progress(0, "åˆå§‹åŒ–...")
        status_text = st.empty()
        result_area = st.empty()

        try:
            # ä¿å­˜ä¸Šå‚³æ–‡ä»¶åˆ°è‡¨æ™‚ä½ç½®
            with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{uploaded_file.name}") as tmp_file:
                tmp_file.write(uploaded_file.read())
                file_path = Path(tmp_file.name)

            progress_bar.progress(10, "æ–‡ä»¶è¼‰å…¥ä¸­...")

            # åˆå§‹åŒ–è™•ç†æœå‹™
            status_text.text("ğŸ”§ åˆå§‹åŒ–LangChainè™•ç†æœå‹™...")
            progress_bar.progress(20, "åˆå§‹åŒ–æœå‹™...")

            ingestion_service = IngestionService()

            progress_bar.progress(30, "é–‹å§‹è™•ç†...")

            # åŸ·è¡Œå¢å¼·è™•ç†
            status_text.text(f"ğŸ¯ è™•ç†ä¸­ ({vlm_strategy})...")

            start_time = time.time()

            # é€™æ˜¯é—œéµ! ä½¿ç”¨æˆ‘å€‘å‰›å¯¦ç¾çš„å¢å¼·è™•ç†æ–¹æ³•
            result = asyncio.run(ingestion_service.ingest_document_enhanced(
                file_path=file_path,
                force_vlm=force_vlm
            ))

            processing_time = time.time() - start_time

            progress_bar.progress(100, "è™•ç†å®Œæˆ! ğŸ‰")

            # é¡¯ç¤ºçµæœ
            with result_area.container():
                if result.get("success"):
                    st.success("âœ… è™•ç†æˆåŠŸå®Œæˆ!")

                    # çµ±è¨ˆæŒ‡æ¨™
                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.metric("è™•ç†æ™‚é–“", f"{processing_time:.2f}s")
                    with col_b:
                        st.metric("åˆ†å¡Šæ•¸", result.get("metadata", {}).get("chunks_created", 0))
                    with col_c:
                        st.metric("åµŒå…¥å‘é‡", result.get("metadata", {}).get("embeddings_created", 0))

                    # ç­–ç•¥å’Œå“è³ªä¿¡æ¯
                    strategy_info = result.get("strategy_used", {})
                    metadata = result.get("metadata", {})

                    st.markdown("#### ğŸ¯ è™•ç†ç­–ç•¥çµæœ")
                    strategy_cols = st.columns(2)

                    with strategy_cols[0]:
                        vlm_used = strategy_info.get("vlm_used", False)
                        vlm_success = strategy_info.get("vlm_success", False)
                        fallback_used = strategy_info.get("fallback_used", False)

                        if fallback_used:
                            st.warning("âš ï¸ ä½¿ç”¨é™ç´šè™•ç†")
                        elif vlm_used and vlm_success:
                            st.success("âœ… VLMè™•ç†æˆåŠŸ")
                        elif vlm_used and not vlm_success:
                            st.warning("âš ï¸ VLMå˜—è©¦å¤±æ•—")
                        else:
                            st.info("ğŸ“ ç›´æ¥è™•ç†")

                    with strategy_cols[1]:
                        quality_level = metadata.get("quality_level", "unknown")
                        # ä¿®å¾©çµ±è¨ˆè¨ˆç®—
                        try:
                            chunk_stats = result.get("statistics", {}).get("chunks", {})
                            if isinstance(chunk_stats, dict) and "total_characters" in chunk_stats:
                                content_len = chunk_stats.get("total_characters", 0)
                            else:
                                content_len = 0
                        except:
                            content_len = 0
                        st.metric("å…§å®¹é•·åº¦", f"{content_len}å­—ç¬¦")
                        st.metric("å“è³ªç­‰ç´š", quality_level.upper())

                    # è©³ç´°çµ±è¨ˆ
                    if "statistics" in result:
                        with st.expander("ğŸ“Š è©³ç´°çµ±è¨ˆ", expanded=False):
                            st.json(result["statistics"])

                else:
                    st.error(f"âŒ è™•ç†å¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")

                    # é¡¯ç¤ºéŒ¯èª¤è©³æƒ…
                    with st.expander("éŒ¯èª¤è©³æƒ…", expanded=True):
                        st.code(result.get('error', ''), language='text')

        except Exception as e:
            st.error(f"âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            st.code(str(e), language='text')

        finally:
            # æ¸…ç†é€²åº¦é¡¯ç¤º
            status_text.empty()
            progress_bar.empty()

            # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
            try:
                if 'file_path' in locals() and file_path.exists():
                    file_path.unlink()
            except:
                pass

# é é¢åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.markdown("""
### ğŸ“– ä½¿ç”¨èªªæ˜

1. **ä¸Šå‚³æ–‡ä»¶**: é¸æ“‡æ”¯æ´çš„æ–‡ä»¶æ ¼å¼ (.pdf, .docx, .txt, .md)
2. **é¸æ“‡ç­–ç•¥**: 
   - è‡ªå‹•åˆ¤æ–·ï¼šæ ¹æ“šæ–‡ä»¶é¡å‹æ™ºèƒ½é¸æ“‡VLMä½¿ç”¨
   - å¼·åˆ¶é–‹å•Ÿï¼šæ¸¬è©¦VLMå¤±æ•—æ™‚çš„é™ç´šæ©Ÿåˆ¶
   - å¼·åˆ¶é—œé–‰ï¼šåªä½¿ç”¨LangChainç›´æ¥è™•ç†
3. **é–‹å§‹è™•ç†**: ç³»çµ±æœƒé¡¯ç¤ºå®Œæ•´çš„è™•ç†æµç¨‹å’Œçµæœ
4. **æŸ¥çœ‹çµæœ**: åŒ…å«è™•ç†æ™‚é–“ã€çµ±è¨ˆæ•¸æ“šå’Œè©³ç´°åˆ†æ

### ğŸ¯ æ¸¬è©¦é‡é»

é€™GUIå°ˆé–€ç”¨æ–¼æ¸¬è©¦æˆ‘å€‘å‰›å¯¦ç¾çš„LangChainå¢å¼·åŠŸèƒ½ï¼š
- **å¤šæ ¼å¼æ”¯æ´**: LangChainè¼‰å…¥å™¨çš„èƒ½åŠ›
- **æ™ºèƒ½ç­–ç•¥**: VLMè‡ªå‹•é¸æ“‡é‚è¼¯
- **é™ç´šæ©Ÿåˆ¶**: VLMå¤±æ•—æ™‚çš„å‚™ç”¨è™•ç†
- **è™•ç†çµ±è¨ˆ**: å®Œæ•´çš„æ•ˆèƒ½å’Œå“è³ªç›£æ§

---
**é–‹ç™¼ä¸­åŠŸèƒ½**: ç›®å‰ç‚ºç¬¬ä¸€éšæ®µæ¸¬è©¦ï¼Œè‘—é‡è™•ç†ç®¡é“é©—è­‰ã€‚
""")
