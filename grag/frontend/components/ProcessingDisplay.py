"""
Processing Display Component
è™•ç†çµæžœé¡¯ç¤ºçµ„ä»¶ï¼Œæä¾›çµ±ä¸€çš„è™•ç†ç‹€æ…‹å’Œçµæžœå±•ç¤º
"""
import streamlit as st
from typing import Dict, List, Any, Optional

class ProcessingDisplay:
    """è™•ç†çµæžœé¡¯ç¤ºçµ„ä»¶"""

    def __init__(self):
        pass

    def show_processing_progress(self, current: int, total: int, message: str = ""):
        """é¡¯ç¤ºè™•ç†é€²åº¦"""
        if total > 0:
            progress = current / total
            st.progress(progress, f"{message} ({current}/{total})")

    def show_file_result(self, result: Dict[str, Any]):
        """é¡¯ç¤ºå–®å€‹æ–‡ä»¶è™•ç†çµæžœ"""
        if result.get("success"):
            st.success("ðŸŽ‰ è™•ç†æˆåŠŸï¼")

            # è™•ç†çµ±è¨ˆ
            metadata = result.get("metadata", {})
            self._show_processing_stats(metadata)

        else:
            st.error(f"âŒ è™•ç†å¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")

    def show_batch_results(self, results: List[Dict[str, Any]]):
        """é¡¯ç¤ºæ‰¹é‡è™•ç†çµæžœ"""
        total_files = len(results)
        successful = sum(1 for r in results if r.get('success', False))
        failed = total_files - successful

        # ç¸½çµçµ±è¨ˆ
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ðŸ“‚ ç¸½æ–‡ä»¶æ•¸", total_files)
        with col2:
            st.metric("âœ… æˆåŠŸè™•ç†", successful)
        with col3:
            st.metric("âŒ è™•ç†å¤±æ•—", failed)

        # è©³ç´°çµæžœ
        st.markdown("### ðŸ“‹ è©³ç´°çµæžœ")

        successful_results = [r for r in results if r.get('success')]
        failed_results = [r for r in results if not r.get('success')]

        # æˆåŠŸçµæžœ
        if successful_results:
            with st.expander(f"âœ… æˆåŠŸçš„æ–‡ä»¶ ({len(successful_results)} å€‹)", expanded=True):
                for result in successful_results:
                    self._show_individual_success(result)

        # å¤±æ•—çµæžœ
        if failed_results:
            with st.expander(f"âŒ å¤±æ•—çš„æ–‡ä»¶ ({len(failed_results)} å€‹)", expanded=False):
                for result in failed_results:
                    self._show_individual_failure(result)

    def _show_individual_success(self, result: Dict[str, Any]):
        """é¡¯ç¤ºå–®å€‹æˆåŠŸçµæžœ"""
        filename = result.get('filename', 'Unknown')
        metadata = result.get('metadata', {})

        st.markdown(f"**{filename}** âœ…")

        # ç°¡è¦çµ±è¨ˆ
        chunks = metadata.get('chunks_created', 0)
        embeddings = metadata.get('embeddings_created', 0)

        col1, col2 = st.columns(2)
        with col1:
            st.caption(f"åˆ†å¡Š: {chunks}")
        with col2:
            st.caption(f"å‘é‡: {embeddings}")

    def _show_individual_failure(self, result: Dict[str, Any]):
        """é¡¯ç¤ºå–®å€‹å¤±æ•—çµæžœ"""
        filename = result.get('filename', 'Unknown')
        error = result.get('error', 'æœªçŸ¥éŒ¯èª¤')

        st.markdown(f"**{filename}** âŒ")
        st.caption(f"éŒ¯èª¤: {error}")

    def _show_processing_stats(self, metadata: Dict[str, Any]):
        """é¡¯ç¤ºè™•ç†çµ±è¨ˆè³‡è¨Š"""
        if not metadata:
            return

        # åŸºæœ¬çµ±è¨ˆ
        processing_time = metadata.get('processing_time', 0)
        chunks_created = metadata.get('chunks_created', 0)
        embeddings_created = metadata.get('embeddings_created', 0)

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("â±ï¸ è™•ç†æ™‚é–“", ".1f")
        with col2:
            st.metric("ðŸ“Š åˆ†å¡Šæ•¸", chunks_created)
        with col3:
            st.metric("ðŸ§® å‘é‡æ•¸", embeddings_created)

        # åµŒå…¥è³‡è¨Š
        if embeddings_created > 0:
            provider_name = metadata.get("embedding_provider", "unknown").upper()
            dimension = metadata.get("embedding_dimension", "N/A")
            st.info(f"ðŸ¤– **åµŒå…¥è³‡è¨Š**: ä½¿ç”¨ {provider_name} æ¨¡åž‹ï¼Œ"
                   f"å‘é‡ç¶­åº¦: {dimension}ï¼Œç”Ÿæˆå‘é‡: {embeddings_created} å€‹")

            # å‘é‡é¡žåž‹çµ±è¨ˆï¼ˆå¦‚æžœæœ‰çš„è©±ï¼‰
            vector_stats = metadata.get("vector_type_stats", {})
            if vector_stats:
                vector_info = []
                for vec_type, count in vector_stats.items():
                    if count > 0:
                        vector_info.append(f"{vec_type}: {count}")
                if vector_info:
                    st.caption(f"å‘é‡é¡žåž‹åˆ†å¸ƒ: {' | '.join(vector_info)}")

    def show_real_time_processing(self, filename: str, stage: str, progress: float):
        """é¡¯ç¤ºå¯¦æ™‚è™•ç†ç‹€æ…‹"""
        st.markdown(f"**æ­£åœ¨è™•ç†**: {filename}")
        st.progress(progress, f"éšŽæ®µ: {stage}")

    def show_processing_summary(self, stats: Dict[str, Any]):
        """é¡¯ç¤ºè™•ç†ç¸½çµ"""
        from grag.frontend.utils import display_metrics_grid

        st.markdown("### ðŸ“Š è™•ç†ç¸½çµ")

        # è½‰æ›ç‚ºå¯é¡¯ç¤ºçš„æ ¼å¼
        display_stats = {}
        for key, value in stats.items():
            display_stats[key] = str(value) if not isinstance(value, str) else value

        display_metrics_grid(display_stats, columns=2)

    def show_error_details(self, errors: List[str]):
        """é¡¯ç¤ºéŒ¯èª¤è©³ç´°è³‡è¨Š"""
        if not errors:
            return

        st.markdown("### âš ï¸ éŒ¯èª¤è©³ç´°è³‡è¨Š")

        with st.expander("é»žæ“ŠæŸ¥çœ‹éŒ¯èª¤è©³æƒ…", expanded=False):
            for i, error in enumerate(errors, 1):
                st.error(f"{i}. {error}")

    def create_processing_report(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """å‰µå»ºè™•ç†å ±å‘Š"""
        total_files = len(results)
        successful = sum(1 for r in results if r.get('success', False))
        failed = total_files - successful

        report = {
            'summary': {
                'total_files': total_files,
                'successful': successful,
                'failed': failed,
                'success_rate': ".1f"
            },
            'performance': self._calculate_performance_stats(results),
            'errors': [r.get('error') for r in results if not r.get('success')]
        }

        return report

    def _calculate_performance_stats(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è¨ˆç®—æ•ˆèƒ½çµ±è¨ˆ"""
        successful_results = [r for r in results if r.get('success')]

        if not successful_results:
            return {}

        avg_processing_time = sum(r.get('metadata', {}).get('processing_time', 0)
                                for r in successful_results) / len(successful_results)

        total_chunks = sum(r.get('metadata', {}).get('chunks_created', 0)
                          for r in successful_results)

        total_embeddings = sum(r.get('metadata', {}).get('embeddings_created', 0)
                             for r in successful_results)

        return {
            'avg_processing_time': ".1f",
            'total_chunks': total_chunks,
            'total_embeddings': total_embeddings,
            'avg_chunks_per_file': total_chunks / len(successful_results),
            'avg_embeddings_per_file': total_embeddings / len(successful_results)
        }
